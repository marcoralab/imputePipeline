'''Snakefile for MIS preparation'''

from snakemake.utils import min_version
min_version("8.0")

import re
import glob
import os
import json

configfile: 'config/config.yaml'

shell.executable('/bin/bash')

# --- Process chromosomes config ---

def parse_chrom(chrs):
    clist = [x.split(":") for x in chrs.split(",")]
    parsed = []
    for chrs in clist:
        if len(chrs) == 2:
            chrs = [str(c) for c in range(int(chrs[0]), int(chrs[1]) + 1)]
        elif len(chrs) != 1:
            raise ValueError("Invalid chromosome list.")
        parsed += chrs
    return parsed

def val_if_config(key, default=None):
    if key in config:
        return config[key]
    return default

if 'chr' in config:
    raise ValueError(
        "Outdated CHR sepec in config. Please use chroms: 'from:to,other'")
elif 'chroms' not in config:
    CHROM = parse_chrom('1:22')
else:
    CHROM = parse_chrom(config['chroms'])

build = val_if_config('build', 'b37')

# --- Process input files from config ---

INPATH = os.path.normpath(config['directory'])

if 'COHORT' in config and config['COHORT']:
    SAMPLES = config["COHORT"]
elif 'SAMPLES' in config and config['SAMPLES']:
    SAMPLES = config["SAMPLES"]
else:
    # Get list of all .bed files
    # Sample is every base name for the .bed files in the INPATH directory
    expression_plink = re.compile(r"(^(.+\/)+)(.*)(?=\.bed)")
    expression_vcf = re.compile(r"(^(.+\/)+)(.*)(\.[bv]cf$|\.vcf\.gz$)")
    expression_vcfchr = re.compile(r"(^(.+\/)+)(.*)\.chr[0-9XYM]{1,2}(\.[bv]cf$|\.vcf\.gz$)")

    SAMPLES = {}
    SAMPLES_plink = [expression_plink.search(x)
                     for x in glob.iglob(INPATH + "/*.bed")] 
    SAMPLES.update(
        {x[3]: {'type': 'plink',
                'fstem': os.path.join(x[1], x[3])}
        for x in SAMPLES_plink})
    vcfs = glob.glob(INPATH + "/*.vcf.gz") + glob.glob(INPATH + "/*.vcf") + glob.glob(INPATH + "/*.bcf")
    SAMPLES_vcfs_all = [
      expression_vcf.search(x) for x in vcfs
      if not re.match(r'.+\.chr[0-9XYM]{1,2}\..+', x)]
    SAMPLES_vcfs_chr = {expression_vcfchr.search(x) for x in vcfs
                if re.match(r'.+\.chr[0-9XYM]{1,2}\..+', x)}
    SAMPLES.update(
        {x[3]: {'type': 'vcf',
                'file': os.path.normpath(x[0])}
        for x in SAMPLES_vcfs_all})
    SAMPLES.update(
        {x[3]: {'type': 'vcf_chr',
                'file': os.path.join(x[1], f'{x[3]}.chr{{chrom}}.{x[4]}')}
        for x in SAMPLES_vcfs_chr})

def first_match(pattern, strings):
    pat = re.compile(pattern)
    for string in strings:
        match = pat.match(string)
        if match:
            return match

# --- Process keep and remove ---
if type(SAMPLES) is dict:
    infiles = SAMPLES
    COHORT = list(infiles.keys())
else:
    COHORT = SAMPLES
    files = (glob.glob(INPATH + "/*.bcf")
             + glob.glob(INPATH + "/*.vcf.gz")
             + glob.glob(INPATH + "/*.vcf") 
             + glob.glob(INPATH + "/*.bed"))
    
    infiles = {}
    for sample in SAMPLES:
        m = first_match(
            f'({INPATH}/{sample})\\.(bcf$|vcf\\.gz$|vcf|bed)',
            files)
        if not m:
            if 'classic' in config and config['classic']:
                infiles[sample] = {
                    'type': 'plink',
                    'fstem': os.path.normpath(f'{INPATH}/{sample}')
                }
                continue
            # Split chrom files not supported for SAMPLE list
            raise Exception(f'Input file not found for {sample}')
        if m[2] == 'bed':
            infiles[sample] = {
                'type': 'plink',
                'fstem': m[1]
            }
        else:
            infiles[sample] = {
                'type': 'vcf',
                'file': os.path.normpath(m[0])
            }

intypes_vcf = all(x['type'] in ['vcf', 'vcf_chr'] for x in infiles.values())
intypes_plink = all(x['type'] == 'plink' for x in infiles.values())

if intypes_plink:
    def build_sampfilt(config):
        def filtstr(x):
            if not (x in config and config[x] and config[x] is not None):
                return None
            elif os.path.isfile(config[x]):
                paramstr = 'keep' if x == 'include_samp' else 'remove'
                return '--{} {}'.format(paramstr, os.path.normpath(config[x]))
            else:
                filt = 'inclusion' if x == 'include_samp' else 'exclusion'
                raise Exception("Invalid {} list: {}.".format(filt, config[x]))
        x = [filtstr(x) for x in ['include_samp', 'exclude_samp']]
        x = [i for i in x if i is not None]
        return ' '.join(x) if x else ''

    def select_sampfilt_files(config):
        include_samp = val_if_config('include_samp', '')
        exclude_samp = val_if_config('exclude_samp', '')
        if not include_samp and not exclude_samp:
            return []
        elif include_samp and exclude_samp:
            return [os.path.normpath(x) for x in [include_samp, exclude_samp]]
        elif include_samp:
            return os.path.normpath(include_samp)
        else:
            return os.path.normpath(exclude_samp)
    
    sampfilt = build_sampfilt(config)

elif intypes_vcf:
    def build_sampfilt(config):
        include_samp = val_if_config('include_samp', '')
        exclude_samp = val_if_config('exclude_samp', '')
        if not include_samp and not exclude_samp:
            return ''
        elif include_samp and exclude_samp:
            raise Exception('Cannot have both sample removal and exclusion.')
        elif include_samp:
            paramstr = os.path.normpath(include_samp)
        else:
            paramstr = '^' + os.path.normpath(exclude_samp)
        return f' --samples-file {paramstr} --force-samples'
    
    def select_sampfilt_files(config):
        include_samp = val_if_config('include_samp', '')
        exclude_samp = val_if_config('exclude_samp', '')
        if not include_samp and not exclude_samp:
            return []
        elif include_samp and exclude_samp:
            raise Exception('Cannot have both sample removal and exclusion.')
        elif include_samp:
            return os.path.normpath(include_samp)
        else:
            return os.path.normpath(exclude_samp)

    sampfilt = build_sampfilt(config)

else:
    sampfilt = False
    if val_if_config('include_samp') or val_if_config('exclude_samp'):
        raise Exception("No filtering in mixed VCF/PLINK input")

# --- Process imputation settings ---

imputation_defaults = {
    'nih': {
        'server': 'NIH',
        'refpanel': 'topmed-r3',
        'population': 'all'},
    'michigan': {
        'server': 'Michigan',
        'refpanel': 'hrc-r1.1',
        'population': 'mixed'}}

if 'imputation' in config and 'default' in config['imputation']:
    default_cfg = config['imputation']['default']
    if ( 'server' in default_cfg and default_cfg['server'].lower() == 'michigan'
         or ('refpanel' in default_cfg
             and default_cfg['refpanel'].lower() == 'hrc-r1.1')):
        default_imp = imputation_defaults['michigan']
    elif ('refpanel' in default_cfg and
          default_cfg['refpanel'].lower() == 'topmed-r3'):
        default_imp = imputation_defaults['nih']
    elif ('refpanel' in default_cfg and default_cfg['refpanel']
          and 'server' in default_cfg and default_cfg['server']
          and 'population' in default_cfg and default_cfg['population']):
        default_imp = default_cfg
    else:
        raise ValueError('Must specify at least server or panel')
    default_imp.update(default_cfg)
else:
    default_imp = imputation_defaults['nih']

imp_settings = dict()
server = dict()
token = dict()

for cht in COHORT:
    imp_settings[cht] = default_imp.copy()
    if 'imputation' in config and cht in config['imputation']:
        imp_settings[cht].update(config['imputation'][cht])
    if 'token' in imp_settings[cht]:
        token[cht] = imp_settings[cht].pop('token')
    else:
        raise ValueError("Must provide either cohort or default API token.")
    server[cht] = imp_settings[cht].pop('server')

# --- Done processing ---

BPLINK = ['bed', 'bim', 'fam']
OUTPATH = os.path.normpath(config["out_dir"])


def flatten(nested):
    flat = []
    for el in nested:
        if not isinstance(el, list):
            flat.append(el)
        else:
            flat += flatten(el)
    return flat


imputed_stem = "{outdir}/imputed/processed"
imputed_outs = dict(
    stat_report="/stats/{cohort}_impStats.html",
    vcf_bycohort="/data/{cohort}_chrall_filtered.vcf.gz",
    vcf_merged="/data/all_chrall_filtered.vcf.gz",
    bgen_bycohort="/data/{cohort}_chrall_filtered.bgen",
    bgen_merged="/data/merged/merged_chrall_filtered.bgen",
    plink_bycohort="/data/{cohort}_chrall_filtered_fixed.{ext}",
    plink_merged="/data/all_chrall_filtered_fixed.{ext}")

def expand_outs(out):
    return expand(imputed_stem + out,
                  cohort=COHORT, ext=BPLINK, outdir=OUTPATH)


imputed = flatten([expand_outs(imputed_outs[x]) for x in config["outputs"]])

wildcard_constraints:
    cohort = r'[^/]+',
    chrom = '|'.join([str(x) for x in CHROM])

rule all:
    input:
        #expand('{outdir}/ready/{cohort}_chr{chrom}.vcf.gz',
        #       cohort=COHORT, chrom=CHROM, outdir=OUTPATH),
        imputed
    localrule: True

include: 'rules/part1.smk'

if config['chr_callrate']:
    include: 'rules/chr_callrate.smk'
elif config['chunk_callrate']:
    include: 'rules/chunk_callrate.smk'
else:
    rule copy_vcf_nocallrate:
        input: 
            tbi = rules.sort_vcf_precallrate.output.tbi,
            vcf = rules.sort_vcf_precallrate.output.vcf
        output:
            tbi = '{outdir}/ready/{cohort}_chr{chrom}.vcf.gz.tbi',
            vcf = '{outdir}/ready/{cohort}_chr{chrom}.vcf.gz'
        localrule: True
        shell:
            '''
cp {input.vcf} {output.vcf}
cp {input.tbi} {output.tbi}
'''

rule apply_irem:
    input:
        irem = '{outdir}/callrate/{cohort}/chrall.irem',
        vcf = '{outdir}/{cohort}_chr{chrom}_preCallcheck.vcf.gz',
        tbi = '{outdir}/{cohort}_chr{chrom}_preCallcheck.vcf.gz.tbi'
    output: '{outdir}/ready/{cohort}_chr{chrom}.vcf.gz'
    threads: 4
    resources:
        mem_mb = 32768,
        time_min = 30
    conda: 'envs/bcftools.yaml'
    shell:
        '''
bcftools view --threads {threads} -S ^{input.irem} -Oz -o {output} {input.vcf}
bcftools index -t {output}
'''

rule submit_imputation:
    input:
        vcf = expand('{{outdir}}/ready/{{cohort}}_chr{chrom}.vcf.gz',
                     chrom=CHROM),
        contig_build = rules.rename_chrom.output.json
    output: '{outdir}/imputation/{cohort}_imputation.json'
    params:
        server = lambda wc: server[wc['cohort']],
        token = lambda wc: token[wc['cohort']],
        imp_settings = lambda wc: imp_settings[wc['cohort']]
    conda: 'envs/apicall.yaml'
    localrule: True
    script: 'scripts/submit_imputation.py'

rule download_imputation:
    input: rules.submit_imputation.output
    output:
        temp(expand('{{outdir}}/imputed/{{cohort}}/chr_{chrom}.zip',
             chrom=CHROM))
    params:
        outpath = '{outdir}/imputed/{cohort}',
        token = rules.submit_imputation.params.token
    conda: 'envs/apicall.yaml'
    localrule: True
    script: 'scripts/download_imputation.py'

rule unzip:
    input:
        zip = '{outdir}/imputed/{cohort}/chr_{chrom}.zip',
        json = rules.submit_imputation.output
    output:
        vcf = '{outdir}/imputed/{cohort}/chr{chrom}.dose.vcf.gz',
        info = '{outdir}/imputed/{cohort}/chr{chrom}.info.gz'
    params:
        odir = '{outdir}/imputed/{cohort}',
    conda: 'envs/p7z.yaml'
    threads: 1
    resources:
        mem_mb = 8192,
        time_min = 30
    shell: '7za e {input.zip} -p$(jq -r .password {input.json}) -o{params.odir}'

postImpute_config = {
    'outputs': config['outputs'],
    'chroms': config['chroms'],
    'directory_in': OUTPATH + '/imputed',
    'directory_out': OUTPATH + '/imputed/processed',
    'qc': config['postqc'],
    'SAMPLES': COHORT,
    'validate_inputs': False,
    'imputePipeline': True}

## --- redo if integrating sample duplication --- ##

if 'include_samp_post' in config:
    postImpute_config['include_samp'] = config['include_samp_post']

if 'exclude_samp_post' in config:
    postImpute_config['exclude_samp'] = config['exclude_samp_post']

### --- ###

if 'version_postImpute' in config:
  version_postImpute = config['version_postImpute']
else:
  version_postImpute = 'v0.4.10'

if re.search(r'/', version_postImpute):
  snakefile_postImpute = os.path.join(
    os.path.abspath(version_postImpute), 'workflow', 'Snakefile')
else:
  snakefile_postImpute = github("marcoralab/postImpute", path="workflow/Snakefile", tag=version_postImpute)

# Post Imputation
module postImpute:
    snakefile: snakefile_postImpute 
    config: postImpute_config

use rule * from postImpute as postImpute_*


plink_cohort_fams = [f"{x['fstem']}.fam" for x in infiles.values() if x['type'] == 'plink']
if 'fix_fam' in config and re.match(r'.+\.fam$', config['fix_fam']):
    plink_cohort_fams.insert(0, config['fix_fam'])


rule cat_fams:
    input: plink_cohort_fams
    output: '{outdir}/prep/all.fam'
    threads: 1
    resources:
        mem_mb = 1024,
        time_min = 180
    shell: r'''
awk 'BEGIN {{
    OFS = "\t"
}}
NF != 6 {{
    print "Error: Number of fields on line " FNR " of " FILENAME " is not 6"
    exit 1
}}
1 {{
    $1 = $1
    print
}}' {input} > {output}
'''

rule fix_fam:
    input:
        oldfam = rules.cat_fams.output,
        newfam = '{outdir}/imputed/processed/data/{cohorts_all}_chrall_filtered.fam'
    output: '{outdir}/imputed/processed/data/{cohorts_all}_chrall_filtered_fixed.fam'
    threads: 1
    resources:
        mem_mb = 1024,
        time_min = 180
    conda: "envs/r.yaml"
    script: 'scripts/fix_fam.R'

rule link_fix_bedbim:
    input:
        bed = '{outdir}/imputed/processed/data/{cohorts_all}_chrall_filtered.bed',
        bim = '{outdir}/imputed/processed/data/{cohorts_all}_chrall_filtered.bim'
    output:
        bed = '{outdir}/imputed/processed/data/{cohorts_all}_chrall_filtered_fixed.bed',
        bim = '{outdir}/imputed/processed/data/{cohorts_all}_chrall_filtered_fixed.bim'
    localrule: True
    shell: '''
ln -rs {input.bed} {output.bed}
ln -rs {input.bim} {output.bim}
'''

